# Base de Dados de Ã“dio contra Pessoas LGBTQIA+ em PortuguÃªs (PT-BR)

ColeÃ§Ã£o de datasets para detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.

## ğŸ¯ Objetivo

Fornecer dados de treinamento e validaÃ§Ã£o para sistemas de detecÃ§Ã£o de discurso de Ã³dio contra pessoas LGBTQIA+ em portuguÃªs brasileiro.

## ğŸ“¢ Contexto Social

Este dataset foi criado a partir de uma **onda de Ã³dio real** sofrida pelo podcast **Entre Amigues** da equipe **CÃ³digo NÃ£o BinÃ¡rio**. Os dados foram coletados durante ataques coordenados nas redes sociais, especialmente no Instagram, onde comentÃ¡rios transfÃ³bicos e de assÃ©dio foram direcionados ao podcast e sua audiÃªncia LGBTQIA+.

### Impacto Social
- **Podcast**: Entre Amigues (CÃ³digo NÃ£o BinÃ¡rio)
- **PerÃ­odo**: Coleta durante onda de Ã³dio coordenada
- **Rede Social**: Instagram (principal fonte)
- **Anotadores**: Equipe especializada em direitos LGBTQIA+
- **Objetivo**: Documentar e combater discurso de Ã³dio real

## ğŸ“Š Datasets IncluÃ­dos

### Datasets Processados (Conforme Modelo Leu)

#### `datasets/dataset_binary_final.csv`
- **27.145 exemplos** de classificaÃ§Ã£o binÃ¡ria (hate/nÃ£o-hate)
- **Colunas**: `id`, `text`, `is_hate`
- **Uso**: Treinamento de modelo binÃ¡rio

#### `datasets/dataset_specialized_final.csv`
- **3.609 exemplos** de classificaÃ§Ã£o especializada
- **Colunas**: `text`, `class`
- **Classes**: `transfobia`, `assedio_insulto`
- **Uso**: Treinamento de modelo especializado

#### `datasets/dataset_manual_final.csv`
- **2.053 exemplos** de anotaÃ§Ãµes manuais
- **Colunas**: `id`, `text`, `is_hate`
- **Uso**: ValidaÃ§Ã£o e fine-tuning

#### `datasets/dataset_toldbr_final.csv`
- **21.000 exemplos** do ToLD-BR processado
- **Colunas**: `text`, `is_hate`
- **Uso**: Dados de treinamento

#### `datasets/dataset_anti_lgbt_final.csv`
- **4.299 exemplos** traduzidos do inglÃªs
- **Colunas**: `id`, `text`, `is_hate`
- **Uso**: Dados de treinamento

#### `datasets/dataset_lgbt_data_final.csv`
- **289 exemplos** de dados LGBT
- **Colunas**: `text`, `is_hate`
- **Uso**: Dados complementares

#### `datasets/dataset_clean_base_final.csv`
- **2.053 exemplos** de base limpa
- **Colunas**: `id`, `text`
- **Uso**: AplicaÃ§Ã£o do modelo

### Datasets Originais

#### `datasets_originais/anti-lgbt-cyberbullying.csv`
- Dataset original em inglÃªs (4.300 exemplos)
- Traduzido para portuguÃªs brasileiro

#### `datasets_originais/told-br.csv`
- Dataset ToLD-BR original (21.000 exemplos)
- AnotaÃ§Ãµes em portuguÃªs brasileiro

#### `datasets_originais/lgbt_data.csv`
- Dataset LGBT Data original (289 exemplos)
- Dados pÃºblicos do Twitter

## ğŸ”’ Privacidade e Ã‰tica

### Medidas de Privacidade
- **Dados pessoais removidos**: Nomes de usuÃ¡rio, IDs, URLs
- **AnonimizaÃ§Ã£o**: IDs substituÃ­dos por hashes
- **NormalizaÃ§Ã£o**: MenÃ§Ãµes (@usuario) â†’ [MENTION]
- **Conformidade**: LGPD/GDPR compliant

### Processamento Aplicado
- URLs â†’ `[URL]`
- @usuario â†’ `[MENTION]`
- #hashtag â†’ `[HASHTAG]`
- RemoÃ§Ã£o de textos < 3 caracteres
- PreservaÃ§Ã£o apenas do conteÃºdo linguÃ­stico

## ğŸ“ˆ EstatÃ­sticas

### DistribuiÃ§Ã£o por Dataset
- **Total de exemplos**: ~60.000
- **Hate speech**: ~15.000 (25%)
- **NÃ£o-hate**: ~45.000 (75%)

### DistribuiÃ§Ã£o por Classe Especializada
- **Transfobia**: ~400 exemplos
- **AssÃ©dio/Insulto**: ~3.400 exemplos

## ğŸš€ Uso

### Carregamento Simples
```python
import pandas as pd

# Dataset binÃ¡rio
df_binary = pd.read_csv('datasets/dataset_binary_final.csv')

# Dataset especializado
df_specialized = pd.read_csv('datasets/dataset_specialized_final.csv')

print(f"Exemplos binÃ¡rios: {len(df_binary)}")
print(f"Exemplos especializados: {len(df_specialized)}")
```

### Treinamento de Modelo
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Carregar dados
train_df = pd.read_csv('datasets/dataset_binary_final.csv')

# Preparar para treinamento
tokenizer = AutoTokenizer.from_pretrained("neuralmind/bert-base-portuguese-cased")
# ... cÃ³digo de treinamento
```

## ğŸ“Š Qualidade dos Dados

### AnotaÃ§Ãµes Manuais
- **Anotadores**: Especialistas em direitos LGBTQIA+
- **Consenso**: ValidaÃ§Ã£o cruzada entre anotadores
- **Cobertura**: 10+ classes especializadas

### ValidaÃ§Ã£o
- **ConsistÃªncia**: VerificaÃ§Ã£o de padrÃµes
- **Bias**: AnÃ¡lise de viÃ©s e estereÃ³tipos
- **Diversidade**: RepresentaÃ§Ã£o de diferentes contextos

## ğŸ¤ ContribuiÃ§Ã£o

### Como Contribuir
1. Fork o repositÃ³rio
2. Adicione novos datasets (seguindo padrÃµes de privacidade)
3. Valide anotaÃ§Ãµes existentes
4. Submeta pull request

### PadrÃµes de Qualidade
- Dados pessoais removidos
- AnotaÃ§Ãµes consistentes
- DocumentaÃ§Ã£o completa
- Testes de validaÃ§Ã£o

## ğŸ“„ LicenÃ§a

MIT License - Veja LICENSE para detalhes.

## ğŸ”— Links Relacionados

- [Radar Social LGBTQIA+](https://github.com/seu-usuario/radar-social-lgbtqia)
- [Hugging Face Datasets](https://huggingface.co/datasets/seu-usuario/base-dados-odio-lgbtqia)

## âš ï¸ Aviso Importante

Este dataset contÃ©m conteÃºdo sensÃ­vel relacionado a discurso de Ã³dio. Use com responsabilidade e sempre considere o impacto Ã©tico de suas aplicaÃ§Ãµes.

## ğŸ“ Contato

Para questÃµes sobre o dataset ou colaboraÃ§Ãµes, entre em contato atravÃ©s das issues do repositÃ³rio.
